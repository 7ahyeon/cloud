
- 이수지 솔루션즈 아키텍트, AWS

# 29CM 데이터 사이언티스트들의 손쉬운 MLOps 인프라 구축 이야기 (레벨 200)
- 온라인 편집숍 29CM의 추천 서비스팀은 전사 공통 미션인 “Guide To Better Choice” 달성을 위해 사용자의 취향에 맞춘 추천 모델을 만들기 위해 노력하고 있습니다. 
- 하지만 애써 만든 추천 모델이 있더라도 이를 운영하고 관리할 수 있는 인프라가 없다면 아무 소용이 없습니다. 
- 본 세션에서는 데이터 사이언티스트만으로 이루어진 작은 팀에서 AWS SageMaker를 활용하여 MLOps 인프라를 구축한 경험을 공유드립니다. 


- 이수지 솔루션즈 아키텍트, AWS
# 리테일 산업에서의 인공지능
# MLOps : 기존 머신러닝 프로세스
- Ad-hoc 데이터 전략 수동 작업
- 자동화의 제한/ 부재

# MLOps : 머신러닝 적용 방안
- 사람p, 기술t, 프로세스c의 결합
- MLOps : ML + Dev + Ops
- tech - processes(거버넌스) - people(협업)

# MLOps : 머신러닝 도입
- 파이프라인별
  - 데이터 파이프 라인 (사진 참고 - machine lifecycle) 
  - 학습 파이프라인
  - 배포 파이프라인(디버깅 포함)
- 오케스트레이션 자동화 : 통합 관리되어야 함

# SageMaker
- **ML lifecycle 간소화**에 도움이 됨

# MWAA
- 디자인 패턴 : MWAA - SageMaker 파이프라인



- 박성준 추천 엔지니어, 29CM
# 29cm MLOps
- Guide to Better Choice
- 연평균 거래액 70%이상 성장
- 견고한 고객 Lock-in : 연간 4회 이상 구매자 10배 성장
- **개인화 추천 서비스**

# 추천 시스템을 위한 MLOps 도입
- 써드 파티 추천 솔루션
- 장점
  - 전문인력 부족시에도 빠른 실행
- 단점
  - 추천 성능 고도화 한계
  - 비즈니스 니즈 대응 어려움
  - 높은 외부 서비스 의존성
- 인하우스 추천 시스템
- 장점
  - 차별화된 추천 성능
  - 다양한 비즈니스 니즈 대응 가능

# MLOps의 역할 : 안정적인 파이프라인 관리와 운영
- 사진 참고(추천서비스 예시)
- 순환 서비스 안정적으로 제공

# 29cm - 데이터 사이언티스트 only
- aws 기술 지원(매니지드 서비스) - Sagemaker / MWAA

# MLOps 구축 : 파이프라인
- processing job -> training job -> model deployment
- 예시 코드(사진 참고)
- 주의사항 : 각 단계별로 파라미터 받는 시점이 다름
- real-time end points 생성 파이프라인
- worker repository - scheduler repository(DAG파일)
- sagemaker bucket <- processing job 데이터 저장 - training job 불러와서 사용
- cloud watch 알람 : real-time end points
- 슬랙 사용

# MLOps 구축 : 무중단 배포
- 에러 발생 시에만 파라미터 스토어 접근 시 비용 절감 가능

# MLOps 도입 기대 효과 : 생산성 향상
- 간편한 실험/테스트 환경
- 손쉬운 배포 (10분안에 DAG파일 작성 및 배포 가능)
- MLOps 구축 6개월 (환경 구축) -> 이후 서비스 적용 기간 단축
  
# future work
- 2-phase recommendation ; candidate generation/ranking candidates(현재 완료)
- 실시간 데이터 기반 추천 ; MAB(multi armed bandit) / Session-based recommendation 


